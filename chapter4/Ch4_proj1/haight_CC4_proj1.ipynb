{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn import datasets, neighbors, tree, ensemble, linear_model, naive_bayes, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]\n",
      "Python 3.11.7\n",
      "sklearn:  1.4.0\n"
     ]
    }
   ],
   "source": [
    "# check versions\n",
    "print(sys.version)\n",
    "!python --version\n",
    "print(\"sklearn: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a random state to be used for all models\n",
    "rand_state = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create random data sets with sklearn datasets class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 50) (2500, 50) (7500,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "# classifier data\n",
    "# using sklearn to create a data set. n_samples is number or rows, n_features is number of columns and n_classes is number of categories to classify\n",
    "xclassifier, yclassifier = datasets.make_classification(n_samples=10000, n_features=50, n_classes=2)\n",
    "\n",
    "xclassifier_train, xclassifier_test, yclassifier_train, yclassifier_test = train_test_split(xclassifier, yclassifier, stratify=yclassifier, shuffle=True)\n",
    "print(xclassifier_train.shape, xclassifier_test.shape, yclassifier_train.shape, yclassifier_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 50) (2500, 50) (7500,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "# regression data\n",
    "xreg, yreg = datasets.make_regression(n_samples=10000, n_features=50, n_targets=1)\n",
    "\n",
    "xreg_train, xreg_test, yreg_train, yreg_test = train_test_split(xreg, yreg, shuffle=True)\n",
    "print(xreg_train.shape, xreg_test.shape, yreg_train.shape, yreg_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of classifier models to be used\n",
    "model_list_clf = [\n",
    "    (ensemble.BaggingClassifier(estimator=linear_model.RidgeClassifier(random_state=rand_state), n_estimators=20), 'BaggingClassifier'),\n",
    "    (ensemble.RandomForestClassifier(random_state=rand_state), 'RandomForestClassifier'),\n",
    "    (ensemble.ExtraTreesClassifier(random_state=rand_state), 'ExtraTreesClassifier'),\n",
    "    (ensemble.AdaBoostClassifier(algorithm='SAMME', random_state=rand_state), 'AdaBoostClassifier'),\n",
    "    (ensemble.GradientBoostingClassifier(random_state=rand_state), 'GradientBoostingClassifier'),\n",
    "    (ensemble.HistGradientBoostingClassifier(random_state=rand_state), 'HistGradientBoostingClassifier')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(clf):\n",
    "    clf.fit(xclassifier_train, yclassifier_train)\n",
    "    yclassifier_pred = clf.predict(xclassifier_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(yclassifier_test, yclassifier_pred)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the data to each model in the model_list_clf list to see which perform best on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "BaggingClassifier\n",
      "Accuracy:  0.8868\n",
      "--------------------------------------------------\n",
      "RandomForestClassifier\n",
      "Accuracy:  0.8944\n",
      "--------------------------------------------------\n",
      "ExtraTreesClassifier\n",
      "Accuracy:  0.8872\n",
      "--------------------------------------------------\n",
      "AdaBoostClassifier\n",
      "Accuracy:  0.8852\n",
      "--------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "Accuracy:  0.8936\n",
      "--------------------------------------------------\n",
      "HistGradientBoostingClassifier\n",
      "Accuracy:  0.8888\n"
     ]
    }
   ],
   "source": [
    "for clf, name in model_list_clf:\n",
    "    print(\"-\"*50)\n",
    "    print(name)\n",
    "    fit_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9284\n"
     ]
    }
   ],
   "source": [
    "clf1 = ensemble.BaggingClassifier(estimator=linear_model.RidgeClassifier(random_state=rand_state))\n",
    "clf2 = naive_bayes.GaussianNB()\n",
    "clf3 = ensemble.HistGradientBoostingClassifier(random_state=rand_state)\n",
    "\n",
    "estimators = [\n",
    "    ('br', clf1),\n",
    "    ('lr', clf2),\n",
    "    ('hgb', clf3),\n",
    "]\n",
    "\n",
    "ensemble_classifier = ensemble.VotingClassifier(estimators=estimators)\n",
    "ensemble_classifier.fit(xclassifier_train, yclassifier_train)\n",
    "\n",
    "yclassifier_pred = ensemble_classifier.predict(xclassifier_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(yclassifier_test, yclassifier_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with ensemble methods:\n",
    "- BaggingClassifier - Accuracy:  0.8868\n",
    "- RandomForestClassifier - Accuracy:  0.8944\n",
    "- ExtraTreesClassifier - Accuracy:  0.8872\n",
    "- AdaBoostClassifier - Accuracy:  0.8852\n",
    "- GradientBoostingClassifier - Accuracy:  0.8936\n",
    "- HistGradientBoostingClassifier - Accuracy:  0.8888\n",
    "\n",
    "Results of ensemble methods used with voting classifier:\n",
    "- Accuracy:  0.9284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of regression models to be used\n",
    "model_list_reg = [\n",
    "    (ensemble.BaggingRegressor(estimator=linear_model.Ridge(random_state=rand_state), n_estimators=20), 'BaggingRegressor'),\n",
    "    (ensemble.RandomForestRegressor(random_state=rand_state), 'RandomForestRegressor'),\n",
    "    (ensemble.ExtraTreesRegressor(random_state=rand_state), 'ExtraTreesRegressor'),\n",
    "    (ensemble.AdaBoostRegressor(random_state=rand_state), 'AdaBoostRegressor'),\n",
    "    (ensemble.GradientBoostingRegressor(random_state=rand_state), 'GradientBoostingRegressor'),\n",
    "    (ensemble.HistGradientBoostingRegressor(random_state=rand_state), 'HistGradientBoostingRegressor')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_reg(reg):\n",
    "    reg.fit(xreg_train, yreg_train)\n",
    "    yreg_pred = reg.predict(xreg_test)\n",
    "\n",
    "    mse = metrics.mean_squared_error(yreg_test, yreg_pred)\n",
    "    print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "BaggingRegressor\n",
      "MSE:  0.0008066532351918132\n",
      "--------------------------------------------------\n",
      "RandomForestRegressor\n",
      "MSE:  8161.828531608716\n",
      "--------------------------------------------------\n",
      "ExtraTreesRegressor\n",
      "MSE:  6681.386187683136\n",
      "--------------------------------------------------\n",
      "AdaBoostRegressor\n",
      "MSE:  9816.239323477608\n",
      "--------------------------------------------------\n",
      "GradientBoostingRegressor\n",
      "MSE:  2902.5682633281417\n",
      "--------------------------------------------------\n",
      "HistGradientBoostingRegressor\n",
      "MSE:  1451.1854870253912\n"
     ]
    }
   ],
   "source": [
    "for reg, name in model_list_reg:\n",
    "    print(\"-\"*50)\n",
    "    print(name)\n",
    "    fit_model_reg(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  4.406927237514981\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('ridge', linear_model.Ridge(random_state=rand_state)),\n",
    "    ('linear', linear_model.LinearRegression()),\n",
    "    ('knr', neighbors.KNeighborsRegressor()),\n",
    "]\n",
    "\n",
    "final_estimator = ensemble.GradientBoostingRegressor(random_state=rand_state)\n",
    "\n",
    "reg = ensemble.StackingRegressor(estimators=estimators, final_estimator=final_estimator)\n",
    "\n",
    "reg.fit(xreg_train, yreg_train)\n",
    "yreg_pred = reg.predict(xreg_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(yreg_test, yreg_pred)\n",
    "print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack of stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.13733201894820282\n"
     ]
    }
   ],
   "source": [
    "estimators_2 = [\n",
    "    ('gbr', ensemble.GradientBoostingRegressor(random_state=rand_state)),\n",
    "    ('rfg', ensemble.RandomForestRegressor(random_state=rand_state)),\n",
    "    ('abr', ensemble.AdaBoostRegressor(random_state=rand_state)),\n",
    "]\n",
    "\n",
    "final_estimator = ensemble.StackingRegressor(estimators=estimators_2, final_estimator=linear_model.Ridge(random_state=rand_state))\n",
    "\n",
    "# run the previous estimators also\n",
    "estimators = [\n",
    "    ('ridge', linear_model.Ridge(random_state=rand_state)),\n",
    "    ('linear', linear_model.LinearRegression()),\n",
    "    ('knr', neighbors.KNeighborsRegressor()),\n",
    "]\n",
    "\n",
    "reg = ensemble.StackingRegressor(estimators=estimators, final_estimator=final_estimator)\n",
    "\n",
    "reg.fit(xreg_train, yreg_train)\n",
    "yreg_pred = reg.predict(xreg_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(yreg_test, yreg_pred)\n",
    "print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  161.36963070130594\n"
     ]
    }
   ],
   "source": [
    "reg1 = ensemble.BaggingRegressor(estimator=linear_model.Ridge(random_state=rand_state))\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg3 = ensemble.HistGradientBoostingRegressor(random_state=rand_state)\n",
    "\n",
    "estimators = [\n",
    "    ('br', reg1),\n",
    "    ('lr', reg2),\n",
    "    ('hgb', reg3),\n",
    "]\n",
    "\n",
    "ensemble_regressor = ensemble.VotingRegressor(estimators=estimators)\n",
    "ensemble_regressor.fit(xreg_train, yreg_train)\n",
    "\n",
    "yreg_pred = ensemble_regressor.predict(xreg_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(yreg_test, yreg_pred)\n",
    "print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble method results\n",
    "- BaggingRegressor - MSE: 0.0008066532351918132\n",
    "- RandomForestRegressor - MSE: 8161.828531608716\n",
    "- ExtraTreesRegressor - MSE: 6681.386187683136\n",
    "- AdaBoostRegressor - MSE: 9816.239323477608\n",
    "- GradientBoostingRegressor - MSE: 2902.5682633281417\n",
    "- HistGradientBoostingRegressor - MSE: 1451.1854870253912\n",
    "##### Stack results\n",
    "- MSE: 4.406927237514981\n",
    "##### Stack of stacks results\n",
    "- MSE: 0.13733201894820282\n",
    "##### Voting Regressor results\n",
    "- MSE: 161.36963070130594"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
