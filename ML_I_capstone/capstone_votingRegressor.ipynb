{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup notebook and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory ./data is not empty.\n"
     ]
    }
   ],
   "source": [
    "# helper function that will check if the data has been unzipped into the data folder and if not, unpack it\n",
    "\n",
    "def unzip_if_empty(directory, zip_file):\n",
    "    \"\"\"Unzip contents if the specified directory is empty.\"\"\"\n",
    "    # Check if the directory is empty\n",
    "    if not os.listdir(directory):  # List is empty if the directory is empty\n",
    "        print(f\"The directory {directory} is empty. Unzipping the file...\")\n",
    "        # Open the ZIP file\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            # Extract all the contents into the directory\n",
    "            zip_ref.extractall(directory)\n",
    "        print(\"Unzip completed.\")\n",
    "    else:\n",
    "        print(f\"The directory {directory} is not empty.\")\n",
    "\n",
    "unzip_if_empty('./data', 'march-machine-learning-mania-2024.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024_tourney_seeds',\n",
       " 'Cities',\n",
       " 'Conferences',\n",
       " 'MConferenceTourneyGames',\n",
       " 'MGameCities',\n",
       " 'MMasseyOrdinals_thruSeason2024_day128',\n",
       " 'MNCAATourneyCompactResults',\n",
       " 'MNCAATourneyDetailedResults',\n",
       " 'MNCAATourneySeedRoundSlots',\n",
       " 'MNCAATourneySeeds',\n",
       " 'MNCAATourneySlots',\n",
       " 'MRegularSeasonCompactResults',\n",
       " 'MRegularSeasonDetailedResults',\n",
       " 'MSeasons',\n",
       " 'MSecondaryTourneyCompactResults',\n",
       " 'MSecondaryTourneyTeams',\n",
       " 'MTeamCoaches',\n",
       " 'MTeamConferences',\n",
       " 'MTeams',\n",
       " 'MTeamSpellings',\n",
       " 'sample_submission',\n",
       " 'WGameCities',\n",
       " 'WNCAATourneyCompactResults',\n",
       " 'WNCAATourneyDetailedResults',\n",
       " 'WNCAATourneySeeds',\n",
       " 'WNCAATourneySlots',\n",
       " 'WRegularSeasonCompactResults',\n",
       " 'WRegularSeasonDetailedResults',\n",
       " 'WSeasons',\n",
       " 'WTeamConferences',\n",
       " 'WTeams',\n",
       " 'WTeamSpellings']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the the csv file names\n",
    "file_names = []\n",
    "for file in os.listdir('./data'):\n",
    "    file_names.append(file[:-4])\n",
    "\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrow that data\n",
    "- We will focus on these files on the dataset:\n",
    "    - MNCAATourneyDetailedResults: details stats from past mens tournament games. we will use the previous two seasons as an indicator of how a team will perform in the tourney. Using the past two seasons, becuase the make up of the team (individual players) will not change much in two years.\n",
    "    - WNCAATourneyDetailedResults: the same information for womens teams.\n",
    "    - MRegularSeasonDetailedResults: detailed stats for each mens team in the regular season. will limit this data to the 2024 season.\n",
    "    - WRegularSeasonDetailedResults: same detailed regular season stats for womens teams.\n",
    "    - 2024_tourney_seeds: starting tournament rankings for both mens and womens teams. a lower seed indicates a stronger team.\n",
    "\n",
    "- We will limit the teams to 64 mens teams and 64 womens teams because there are only 64 teams invited to play in the end of season tournament. \n",
    "- Using these files we will assemble one dataset and limit it to two years of historical performance\n",
    "- will use the MTeams and WTeams files at the end to map team names to team ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "m_reg_season = pd.read_csv('./data/MRegularSeasonDetailedResults.csv')\n",
    "w_reg_season = pd.read_csv('./data/WRegularSeasonDetailedResults.csv')\n",
    "m_hist_tourney = pd.read_csv('./data/MNCAATourneyDetailedResults.csv')\n",
    "w_hist_tourney = pd.read_csv('./data/WNCAATourneyDetailedResults.csv')\n",
    "tourney_seeds = pd.read_csv('./data/2024_tourney_seeds.csv')\n",
    "m_teams = pd.read_csv('./data/MTeams.csv')\n",
    "w_teams = pd.read_csv('./data/WTeams.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble dataframes into one df for training\n",
    "- first we will concat the mens and womens data frames into one data frame\n",
    "- then we will combine the regular season data and historical tournament data.\n",
    "- the goal is to create a dataframe where a single row is a single game. the label for each row will be a true or false if the team won that particular game.\n",
    "- adding the tournament seeds for each team will add a feature for training.\n",
    "- we can also use the seeds to make a baseline estimate of winners. we can simply pick the higher seed for any particular matchup and that will give a goal for the model to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2003      10     1104      68     1328      62    N      0    27    58   \n",
       "1    2003      10     1272      70     1393      63    N      0    26    62   \n",
       "2    2003      11     1266      73     1437      61    N      0    24    58   \n",
       "3    2003      11     1296      56     1457      50    N      0    18    38   \n",
       "4    2003      11     1400      77     1208      71    N      0    30    61   \n",
       "\n",
       "   ...  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0  ...     10    16    22   10   22     8   18     9     2   20  \n",
       "1  ...     24     9    20   20   25     7   12     8     6   16  \n",
       "2  ...     26    14    23   31   22     9   12     2     5   23  \n",
       "3  ...     22     8    15   17   20     9   19     4     3   23  \n",
       "4  ...     16    17    27   21   15    12   10     7     1   14  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_reg_season.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3103</td>\n",
       "      <td>63</td>\n",
       "      <td>3237</td>\n",
       "      <td>49</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3104</td>\n",
       "      <td>73</td>\n",
       "      <td>3399</td>\n",
       "      <td>68</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3110</td>\n",
       "      <td>71</td>\n",
       "      <td>3224</td>\n",
       "      <td>59</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3111</td>\n",
       "      <td>63</td>\n",
       "      <td>3267</td>\n",
       "      <td>58</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3119</td>\n",
       "      <td>74</td>\n",
       "      <td>3447</td>\n",
       "      <td>70</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2010      11     3103      63     3237      49    H      0    23    54   \n",
       "1    2010      11     3104      73     3399      68    N      0    26    62   \n",
       "2    2010      11     3110      71     3224      59    A      0    29    62   \n",
       "3    2010      11     3111      63     3267      58    A      0    27    52   \n",
       "4    2010      11     3119      74     3447      70    H      1    30    74   \n",
       "\n",
       "   ...  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0  ...     13     6    10   11   27    11   23     7     6   19  \n",
       "1  ...     21    14    27   14   26     7   20     4     2   27  \n",
       "2  ...     14    19    23   17   23     8   15     6     0   15  \n",
       "3  ...     26    16    25   22   22    15   11    14     5   14  \n",
       "4  ...     17    11    21   21   32    12   14     4     2   14  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_reg_season.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to each df that indicates if it is mens data or womens. will make this a boolean so it can be 0 or 1\n",
    "m_reg_season['mens_data'] = True\n",
    "w_reg_season['mens_data'] = False\n",
    "\n",
    "# limit regular season data to only 2024 and then concat the mens and womens data into one df\n",
    "m_reg_season = m_reg_season[m_reg_season['Season'] == 2024]\n",
    "w_reg_season = w_reg_season[w_reg_season['Season'] == 2024]\n",
    "reg_season = pd.concat([m_reg_season, w_reg_season], axis=0)\n",
    "\n",
    "# add a column that indicates if each row (game) is a tournament game. will all be false for this df\n",
    "reg_season['tourney_game'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>mens_data</th>\n",
       "      <th>tourney_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107634</th>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "      <td>64</td>\n",
       "      <td>1329</td>\n",
       "      <td>59</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107635</th>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>1103</td>\n",
       "      <td>81</td>\n",
       "      <td>1355</td>\n",
       "      <td>75</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107636</th>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>105</td>\n",
       "      <td>1287</td>\n",
       "      <td>73</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107637</th>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>1112</td>\n",
       "      <td>122</td>\n",
       "      <td>1288</td>\n",
       "      <td>59</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107638</th>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>1114</td>\n",
       "      <td>71</td>\n",
       "      <td>1402</td>\n",
       "      <td>66</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  \\\n",
       "107634    2024       0     1101      64     1329      59    A      0    26   \n",
       "107635    2024       0     1103      81     1355      75    A      0    26   \n",
       "107636    2024       0     1104     105     1287      73    H      0    32   \n",
       "107637    2024       0     1112     122     1288      59    H      0    42   \n",
       "107638    2024       0     1114      71     1402      66    H      0    22   \n",
       "\n",
       "        WFGA  ...  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  mens_data  \\\n",
       "107634    57  ...    20    6   26    13   12     9     2   16       True   \n",
       "107635    57  ...    13    5   18    14   12     8     2   17       True   \n",
       "107636    57  ...    19   11   15     7   14     6     3   25       True   \n",
       "107637    76  ...    15    6   17    10   25     3     6   25       True   \n",
       "107638    59  ...    22   17   31    14   22     2     4   23       True   \n",
       "\n",
       "        tourney_game  \n",
       "107634         False  \n",
       "107635         False  \n",
       "107636         False  \n",
       "107637         False  \n",
       "107638         False  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_season.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same for historical tournament data. since we do not have 2024 tournament data, limit this data to the previous two years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to each df that indicates if it is mens data or womens. will make this a boolean so it can be 0 or 1\n",
    "m_hist_tourney['mens_data'] = True\n",
    "w_hist_tourney['mens_data'] = False\n",
    "\n",
    "# limit tournament data to only 2022 and 2023 and then concat the mens and womens data into one df\n",
    "m_hist_tourney = m_hist_tourney[m_hist_tourney['Season'] >= 2022]\n",
    "w_hist_tourney = w_hist_tourney[w_hist_tourney['Season'] >= 2022]\n",
    "hist_tourney = pd.concat([m_hist_tourney, w_hist_tourney], axis=0)\n",
    "\n",
    "# add a column that indicates if each row (game) is a tournament game. will all be true for this df\n",
    "hist_tourney['tourney_game'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "      <th>mens_data</th>\n",
       "      <th>tourney_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>2022</td>\n",
       "      <td>134</td>\n",
       "      <td>1231</td>\n",
       "      <td>66</td>\n",
       "      <td>1461</td>\n",
       "      <td>58</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>2022</td>\n",
       "      <td>134</td>\n",
       "      <td>1411</td>\n",
       "      <td>76</td>\n",
       "      <td>1394</td>\n",
       "      <td>67</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>2022</td>\n",
       "      <td>135</td>\n",
       "      <td>1323</td>\n",
       "      <td>89</td>\n",
       "      <td>1353</td>\n",
       "      <td>87</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>2022</td>\n",
       "      <td>135</td>\n",
       "      <td>1460</td>\n",
       "      <td>93</td>\n",
       "      <td>1136</td>\n",
       "      <td>82</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>2022</td>\n",
       "      <td>136</td>\n",
       "      <td>1116</td>\n",
       "      <td>75</td>\n",
       "      <td>1436</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  \\\n",
       "1181    2022     134     1231      66     1461      58    N      0    26   \n",
       "1182    2022     134     1411      76     1394      67    N      0    23   \n",
       "1183    2022     135     1323      89     1353      87    N      2    37   \n",
       "1184    2022     135     1460      93     1136      82    N      0    29   \n",
       "1185    2022     136     1116      75     1436      71    N      0    24   \n",
       "\n",
       "      WFGA  ...  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  mens_data  \\\n",
       "1181    62  ...    18    7   23     6   18     2     1   17       True   \n",
       "1182    55  ...    19    7   29    17    8     9     3   22       True   \n",
       "1183    72  ...     6   13   28    22   13     1     6   15       True   \n",
       "1184    61  ...    23   10   22     7   13    11     5   24       True   \n",
       "1185    56  ...    17    5   26    13    6     1     1   21       True   \n",
       "\n",
       "      tourney_game  \n",
       "1181          True  \n",
       "1182          True  \n",
       "1183          True  \n",
       "1184          True  \n",
       "1185          True  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_tourney.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine historical tournament data and 2024 regular season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([hist_tourney, reg_season], axis=0)\n",
    "\n",
    "# add seeds column\n",
    "data = pd.merge(data, tourney_seeds, left_on='WTeamID', right_on='TeamID', how='left')\n",
    "data.drop(columns=['Tournament', 'TeamID'], inplace=True) # drop some redundant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign \"Seed\" to teams without one\n",
    "- if a team does not have a seed it indicates that they were not invited to play in the 2024 tournament.\n",
    "- these teams may have played in the tournament in previous years, so rather than dropping these rows we will assign a \"Seed\" of 20. This will indicate that they were not a strong team in 2024.\n",
    "- Teams that are seeded have a value with a letter followed by a number between 1 and 16. we are only interested in the number so we will trim the letter from seeded teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Seed'] = data['Seed'].fillna('20')\n",
    "data['Seed'] = data['Seed'].apply(lambda x: x[1:] if len(x) == 3 else x)\n",
    "\n",
    "# convert to an int\n",
    "data['Seed'] = data['Seed'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'H', 'A'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['WLoc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WLoc column\n",
    "- The 'WLoc' column indicates the location of the game for the winning team (WTeamID).\n",
    "    - N = neautral location\n",
    "    - H = home game\n",
    "    - A = away game\n",
    "- will need to encode these to a numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas \"get_dummies\" method to one hot encode 'WLoc' feature\n",
    "data = pd.get_dummies(data, columns=['WLoc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add \"IsWin\" feature\n",
    "- In order to add a feature that will be the target (i.e. whether or not the team won the game) we will need to reorganize the data\n",
    "- assign each row a \"gameID\" to give each game a unique value\n",
    "- Split the winner and loser features into seperate dataframes and the rename them to neutral names. for example, instead of \"WTeamID\" for winning team ID, just TeamID\n",
    "- Add an \"IsWin\" column to each df with the appropriate value, and then concat them back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a gameID col\n",
    "data['gameID'] = range(1, len(data) + 1)\n",
    "\n",
    "# split data into winners and losers\n",
    "winner_cols = ['gameID', 'WTeamID', 'WScore', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst',\n",
    "    'WTO', 'WStl', 'WBlk', 'WPF', 'mens_data', 'tourney_game', 'Seed', 'WLoc_A', 'WLoc_H', 'WLoc_N']\n",
    "\n",
    "loser_cols = ['gameID', 'LTeamID', 'LScore', 'NumOT', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst',\n",
    "    'LTO', 'LStl', 'LBlk', 'LPF', 'mens_data', 'tourney_game', 'Seed', 'WLoc_A', 'WLoc_H', 'WLoc_N']\n",
    "\n",
    "winners = data[winner_cols]\n",
    "loosers = data[loser_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to neutral names\n",
    "winners = winners.rename(columns={'WTeamID': 'TeamID', 'WScore': 'Score', 'WFGM': 'FGM', 'WFGA': 'FGA', 'WFGM3': 'FGM3',\n",
    "    'WFGA3': 'FGA3', 'WFTM': 'FTM', 'WFTA': 'FTA', 'WOR': 'OR', 'WDR': 'DR', 'WAst': 'Ast', 'WTO': 'TO', 'WStl': 'Stl', 'WBlk': 'Blk',\n",
    "    'WPF': 'PF', 'WLoc_A': 'Loc_A', 'WLoc_H': 'Loc_H', 'WLoc_N': 'Loc_N'})\n",
    "\n",
    "loosers = loosers.rename(columns={'LTeamID': 'TeamID', 'LScore': 'Score', 'LFGM': 'FGM', 'LFGA': 'FGA', 'LFGM3': 'FGM3', 'LFGA3': 'FGA3',\n",
    "    'LFTM': 'FTM', 'LFTA': 'FTA', 'LOR': 'OR', 'LDR': 'DR', 'LAst': 'Ast', 'LTO': 'TO', 'LStl': 'Stl', 'LBlk': 'Blk', 'LPF': 'PF', 'WLoc_A': 'Loc_A',\n",
    "    'WLoc_H': 'Loc_H', 'WLoc_N': 'Loc_N' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \"IsWin\" column with appropriate value\n",
    "winners['IsWin'] = True\n",
    "loosers['IsWin'] = False\n",
    "\n",
    "# for loosers flip the value of the location columns\n",
    "\n",
    "# temporarily split the neutral games out\n",
    "neutral = loosers[loosers['Loc_N'] == True]\n",
    "loosers = loosers[loosers['Loc_N'] == False]\n",
    "\n",
    "# flip values\n",
    "loosers['Loc_A'] = ~loosers['Loc_A']\n",
    "loosers['Loc_H'] = ~loosers['Loc_H']\n",
    "\n",
    "# concat neutral games back in\n",
    "loosers = pd.concat([loosers, neutral], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add opponent stats columns\n",
    "- concat winners and loosers back together width wise and rename the columns to indicate they are opponent game stats\n",
    "- combine winners and loosers back together vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_opponent = loosers.add_prefix('opp_')\n",
    "loser_opponent = winners.add_prefix('opp_')\n",
    "\n",
    "winners = pd.concat([winners, loser_opponent], axis=1)\n",
    "loosers = pd.concat([loosers, winner_opponent], axis=1)\n",
    "\n",
    "data = pd.concat([winners, loosers], axis=0)\n",
    "\n",
    "# drop redundant columns\n",
    "data.drop(columns=['opp_gameID', 'opp_mens_data', 'opp_tourney_game', 'opp_Loc_A', 'opp_Loc_H', 'opp_Loc_N', 'opp_IsWin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('prepared_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create aggregate data for each team\n",
    "- in order to predict one teams performace against another, we will create some data aggregations for each team. i.e. average score, winning percentage, and averages or medians of other game stats.\n",
    "- In the final product, the user will be asked to enter two teams and the model will use these aggregated stats for those teams as inputs to make a prediction of which team will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data aggregations into home, away and neutral location games\n",
    "neutral_games = data[data['Loc_N'] == True]\n",
    "home_games = data[data['Loc_H'] == True]\n",
    "away_games = data[data['Loc_A'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform aggregations for each team\n",
    "neutral_games = neutral_games.groupby('TeamID').agg({\n",
    "    'Score': 'mean',   # Average score\n",
    "    'FGM': 'mean',     # Average field goals made\n",
    "    'FGA': 'mean',     # Average field goals attempted\n",
    "    'FGM3': 'mean',    # Average three-point field goals made\n",
    "    'FGA3': 'mean',    # Average three-point field goals attempted\n",
    "    'FTM': 'mean',     # Average free throws made\n",
    "    'FTA': 'mean',     # Average free throws attempted\n",
    "    'OR': 'mean',      # Average offensive rebounds\n",
    "    'DR': 'mean',      # Average defensive rebounds\n",
    "    'Ast': 'mean',     # Average assists\n",
    "    'TO': 'mean',      # Average turnovers\n",
    "    'Stl': 'mean',     # Average steals\n",
    "    'Blk': 'mean',     # Average blocks\n",
    "    'PF': 'mean'       # Average personal fouls\n",
    "}).reset_index()\n",
    "\n",
    "home_games = home_games.groupby('TeamID').agg({\n",
    "    'Score': 'mean',\n",
    "    'FGM': 'mean',\n",
    "    'FGA': 'mean',\n",
    "    'FGM3': 'mean',\n",
    "    'FGA3': 'mean',\n",
    "    'FTM': 'mean',\n",
    "    'FTA': 'mean',\n",
    "    'OR': 'mean',\n",
    "    'DR': 'mean',\n",
    "    'Ast': 'mean',\n",
    "    'TO': 'mean',\n",
    "    'Stl': 'mean',\n",
    "    'Blk': 'mean',\n",
    "    'PF': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "away_games = away_games.groupby('TeamID').agg({\n",
    "    'Score': 'mean',\n",
    "    'FGM': 'mean',\n",
    "    'FGA': 'mean',\n",
    "    'FGM3': 'mean',\n",
    "    'FGA3': 'mean',\n",
    "    'FTM': 'mean',\n",
    "    'FTA': 'mean',\n",
    "    'OR': 'mean',\n",
    "    'DR': 'mean',\n",
    "    'Ast': 'mean',\n",
    "    'TO': 'mean',\n",
    "    'Stl': 'mean',\n",
    "    'Blk': 'mean',\n",
    "    'PF': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "neutral_games.to_csv('neutral_game_aggregations.csv', index=False)\n",
    "home_games.to_csv('home_game_aggregations.csv', index=False)\n",
    "away_games.to_csv('away_game_aggregations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two rows for each game. one for each team\n",
    "data.sort_values(by='gameID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop opp_NumOT since it is redundanct\n",
    "del data['opp_NumOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column info\n",
    "- gameID: unique id for each game. there will be two rows for each id. one for each team\n",
    "- TeamID: id to identify each team\n",
    "- Score: teams score for that game\n",
    "- NumOT: if the game went into overtime, this number indicates the number of overtime periods played\n",
    "- FGM: field goals made\n",
    "- FGA: field goals attempted\n",
    "- FGM3: 3-point field goals made\n",
    "- FGA3: 3-point field goals attempted\n",
    "- FTM: free throws made\n",
    "- FTA: free throws attempted\n",
    "- OR: offensive rebounds\n",
    "- DR: defensive rebounds\n",
    "- Ast: assists\n",
    "- TO: turn overs\n",
    "- Stl: steals\n",
    "- Blk: blocks\n",
    "- PF: total personal fouls commited by the team in that game\n",
    "- mens_data: if this is a mens game\n",
    "- tourney_game: if this is a tournament game\n",
    "- Seed: the teams seed in the 2024 NCAA tourney. if the team was not invited to the 2024 tournament a seed of 20 was assigned to indicate a weaker team\n",
    "- Loc_A: if the location the game was away\n",
    "- Loc_H: if the location the game was home\n",
    "- Loc_N: if the location the game was neutral\n",
    "- IsWin: team won the game\n",
    "- opp_TeamID: opponents teamID\n",
    "- opp_Score: opponents score\n",
    "- opp_FGM: opponent field goals made\n",
    "- opp_FGA: opponent field goals attempted\n",
    "- opp_FGM3: opponent 3-point field goals made\n",
    "- opp_FGA3: opponent 3-point field goals attempted\n",
    "- opp_FTM: opponent free throws made\n",
    "- opp_FTA: opponent free throws attempted\n",
    "- opp_OR: opponent offensive rebounds\n",
    "- opp_DR: opponent defensive rebounds\n",
    "- opp_Ast: opponent assists\n",
    "- opp_TO: opponent turn overs\n",
    "- opp_Stl: opponent steals\n",
    "- opp_Blk: opponent blocks\n",
    "- opp_PF: opponent total personal fouls commited in that game\n",
    "- opp_Seed: opponent seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# selected features\n",
    "features = [\n",
    "    # 'gameID',\n",
    "    # 'TeamID',\n",
    "    'Score',\n",
    "    # 'NumOT',\n",
    "    'FGM',\n",
    "    'FGA',\n",
    "    'FGM3',\n",
    "    'FGA3',\n",
    "    'FTM',\n",
    "    'FTA',\n",
    "    'OR',\n",
    "    'DR',\n",
    "    'Ast',\n",
    "    'TO',\n",
    "    'Stl',\n",
    "    'Blk',\n",
    "    'PF',\n",
    "    # 'mens_data',\n",
    "    # 'tourney_game',\n",
    "    'Seed',\n",
    "    'Loc_A',\n",
    "    'Loc_H',\n",
    "    'Loc_N',\n",
    "    'IsWin',\n",
    "    # 'opp_TeamID',\n",
    "    'opp_Score',\n",
    "    'opp_FGM',\n",
    "    'opp_FGA',\n",
    "    'opp_FGM3',\n",
    "    'opp_FGA3',\n",
    "    'opp_FTM',\n",
    "    'opp_FTA',\n",
    "    'opp_OR',\n",
    "    'opp_DR',\n",
    "    'opp_Ast',\n",
    "    'opp_TO',\n",
    "    'opp_Stl',\n",
    "    'opp_Blk',\n",
    "    'opp_PF',\n",
    "    'opp_Seed'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "data[features].hist(bins=30, figsize=(15, 14))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "correlation_matrix['IsWin'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats correlated with winning games\n",
    "- Highly correlated:\n",
    "    - Score (duh)\n",
    "    - Field goals made\n",
    "    - Assists\n",
    "    - Defensive rebounds\n",
    "- Somewhat correlated:\n",
    "    - Free throws made\n",
    "    - 3-point field goals made\n",
    "    - If the game was played at home\n",
    "- Low correlation:\n",
    "    - Steals\n",
    "    - Blocks\n",
    "    - Offensive rebounds (this is surprising since offensive rebounds grant a team an extra offensive possision and another opportunity to score)\n",
    "- Negative correlations (detrimental to winning the game):\n",
    "    - Turnovers\n",
    "    - Personal Fouls\n",
    "    - If the game was played away\n",
    "\n",
    "- Opponent stat correlations mirror these. i.e. an opponent that has a lot of field goals made is detrimental to winning the game\n",
    "- This gives a good idea of which features to focus on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random state\n",
    "rand_state = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split target from data\n",
    "X = data.copy()\n",
    "X.drop(columns=[\n",
    "    'IsWin',\n",
    "    'gameID',\n",
    "    'NumOT',\n",
    "    'mens_data',\n",
    "    'tourney_game',\n",
    "    'Seed',\n",
    "    'opp_Seed'\n",
    "], inplace=True)\n",
    "y = data['IsWin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble, naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, Ridge, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both training and testing data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test some models and their accuracy on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"{model.__class__.__name__}:\")\n",
    "    print(f\"Accuracy = {accuracy:.4f}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    KNeighborsClassifier(),\n",
    "    RidgeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    SVC(),\n",
    "    xgboost.XGBClassifier(),\n",
    "    SGDClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    AdaBoostClassifier(algorithm='SAMME'),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    evaluate_classifier(model, X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial results\n",
    "- Best performing models are LogisticRegression, SVC and XGBClassifier\n",
    "- will try to reduce dimensions and see how it affects the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# reduce to the number of dimensions that will contain 95% of the variance of the data\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    evaluate_classifier(model, X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ineffective dimensionality reduction\n",
    "- using pca reduction significantly reduced accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of ensemble classifier models to try\n",
    "classifier_models = [\n",
    "    (ensemble.BaggingClassifier(estimator=LogisticRegression(random_state=rand_state, max_iter=1000), n_estimators=20), 'BaggingClassifier'),\n",
    "    (ensemble.RandomForestClassifier(random_state=rand_state), 'RandomForestClassifier'),\n",
    "    (ensemble.ExtraTreesClassifier(random_state=rand_state), 'ExtraTreesClassifier'),\n",
    "    (ensemble.AdaBoostClassifier(algorithm='SAMME', random_state=rand_state), 'AdaBoostClassifier'),\n",
    "    (ensemble.GradientBoostingClassifier(random_state=rand_state), 'GradientBoostingClassifier'),\n",
    "    (ensemble.HistGradientBoostingClassifier(random_state=rand_state), 'HistGradientBoostingClassifier'),\n",
    "    (xgboost.XGBClassifier(random_state=rand_state), 'XGBoostClassifer')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in classifier_models:\n",
    "    evaluate_classifier(model, X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ensemble.BaggingClassifier(estimator=RidgeClassifier(random_state=rand_state))\n",
    "clf2 = naive_bayes.GaussianNB()\n",
    "clf3 = ensemble.HistGradientBoostingClassifier(random_state=rand_state)\n",
    "clf4 = ensemble.GradientBoostingClassifier(random_state=rand_state)\n",
    "clf5 = xgboost.XGBClassifier(random_state=rand_state)\n",
    "\n",
    "estimators = [\n",
    "    ('bagging', clf1),\n",
    "    ('naive_bayes', clf2),\n",
    "    ('HistGradient', clf3),\n",
    "    ('GrandientBoost', clf4),\n",
    "    ('XGBoost', clf5)\n",
    "]\n",
    "\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=estimators)\n",
    "voting_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "yclassifier_pred = voting_classifier.predict(X_test_scaled)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, yclassifier_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of regression models to be used\n",
    "model_list_reg = [\n",
    "    (ensemble.BaggingRegressor(estimator=Ridge(random_state=rand_state), n_estimators=20), 'BaggingRegressor'),\n",
    "    (ensemble.RandomForestRegressor(random_state=rand_state), 'RandomForestRegressor'),\n",
    "    (ensemble.ExtraTreesRegressor(random_state=rand_state), 'ExtraTreesRegressor'),\n",
    "    (ensemble.AdaBoostRegressor(random_state=rand_state), 'AdaBoostRegressor'),\n",
    "    (ensemble.GradientBoostingRegressor(random_state=rand_state), 'GradientBoostingRegressor'),\n",
    "    (ensemble.HistGradientBoostingRegressor(random_state=rand_state), 'HistGradientBoostingRegressor'),\n",
    "    (xgboost.XGBRegressor(random_state=rand_state), 'XGBRegressor')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_reg(reg):\n",
    "    reg.fit(X_train_scaled, y_train)\n",
    "    yreg_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "    mse = metrics.mean_squared_error(y_test, yreg_pred)\n",
    "    print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg, name in model_list_reg:\n",
    "    print(\"-\"*1000)\n",
    "    print(name)\n",
    "    fit_model_reg(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('ridge', Ridge(random_state=rand_state)),\n",
    "    ('linear', LinearRegression()),\n",
    "    ('knr', KNeighborsRegressor()),\n",
    "    ('xgboost', xgboost.XGBRegressor(random_state=rand_state))\n",
    "]\n",
    "\n",
    "final_estimator = ensemble.HistGradientBoostingRegressor(random_state=rand_state)\n",
    "\n",
    "stack_regressor = ensemble.StackingRegressor(estimators=estimators, final_estimator=final_estimator)\n",
    "\n",
    "stack_regressor.fit(X_train_scaled, y_train)\n",
    "yreg_pred = stack_regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test, yreg_pred)\n",
    "print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack of stacks\n",
    "- use best performing ensemble regression models as the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_2 = [\n",
    "    ('gradientboot', ensemble.GradientBoostingRegressor(random_state=rand_state)),\n",
    "    ('histgradient', ensemble.HistGradientBoostingRegressor(random_state=rand_state)),\n",
    "    ('xgboost', xgboost.XGBRegressor(random_state=rand_state)),\n",
    "    ('bagging', ensemble.BaggingRegressor(random_state=rand_state))\n",
    "]\n",
    "\n",
    "final_estimator = ensemble.StackingRegressor(\n",
    "    estimators=estimators_2,\n",
    "    final_estimator=ensemble.HistGradientBoostingRegressor(random_state=rand_state)\n",
    ")\n",
    "\n",
    "# run the previous estimators also\n",
    "estimators = [\n",
    "    ('ridge', Ridge(random_state=rand_state)),\n",
    "    ('linear', LinearRegression()),\n",
    "    ('knr', KNeighborsRegressor()),\n",
    "    ('xgboost', xgboost.XGBRegressor(random_state=rand_state))\n",
    "]\n",
    "\n",
    "stack_of_stacks_reg = ensemble.StackingRegressor(estimators=estimators, final_estimator=final_estimator)\n",
    "\n",
    "stack_of_stacks_reg.fit(X_train_scaled, y_train)\n",
    "yreg_pred = stack_of_stacks_reg.predict(X_test_scaled)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test, yreg_pred)\n",
    "print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = ensemble.GradientBoostingRegressor(random_state=rand_state)\n",
    "reg2 = ensemble.HistGradientBoostingRegressor(random_state=rand_state)\n",
    "reg3 = xgboost.XGBRegressor(random_state=rand_state)\n",
    "reg4 = ensemble.BaggingRegressor(random_state=rand_state)\n",
    "\n",
    "estimators = [\n",
    "    ('gradientBoost', reg1),\n",
    "    ('histGradient', reg2),\n",
    "    ('xgbRegressor', reg3),\n",
    "    ('bagging', reg4),\n",
    "]\n",
    "\n",
    "voting_regressor = ensemble.VotingRegressor(estimators=estimators)\n",
    "voting_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "yreg_pred = voting_regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test, yreg_pred)\n",
    "print(\"MSE: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "#### Initial models\n",
    "- LogisticRegression: Accuracy = 0.8840\n",
    "\n",
    "### After PCA dimensionality reduction\n",
    "- XGBClassifier: Accuracy = 0.5016\n",
    "\n",
    "### Ensemble classification models\n",
    "- BaggingClassifier: Accuracy = 0.8822\n",
    "\n",
    "### Ensemble Voting Classifiction model\n",
    "- BaggingClassifier: Accuracy = 0.8822\n",
    "\n",
    "### Ensemble Regression model\n",
    "- HistGradientBoostingRegressor: MSE = 0.10200270964882302\n",
    "\n",
    "### Ensemble Stacking regressor\n",
    "- estimators used:\n",
    "    - Ridge\n",
    "    - LinearRegression\n",
    "    - KNeighborsRegressor\n",
    "    - XGBRegressor\n",
    "    - Final estimator: ensemble.HistGradientBoostingRegressor\n",
    "    - MSE:  0.0887182854997212\n",
    "\n",
    "### Ensemble Stack of Stacks regressor\n",
    "- Additional models used as estimators:\n",
    "    - ensemble.GradientBoostingRegressor\n",
    "    - ensemble.HistGradientBoostingRegressor\n",
    "    - xgboost.XGBRegressor\n",
    "    - ensemble.BaggingRegressor\n",
    "    - Previous stack used as the final estimator\n",
    "- MSE:  0.08994140523121094\n",
    "\n",
    "### Voting Ensemble Regressor\n",
    "- Estimators used:\n",
    "    - ensemble.GradientBoostingRegressor\n",
    "    - ensemble.HistGradientBoostingRegressor\n",
    "    - xgboost.XGBRegressor\n",
    "    - ensemble.BaggingRegressor\n",
    "- MSE:  0.10309174643982315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Models to determine accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logRegressor = LogisticRegression(max_iter=1000, random_state=rand_state)\n",
    "baggingClassifier = ensemble.BaggingClassifier(estimator=LogisticRegression(random_state=rand_state, max_iter=1000), n_estimators=20)\n",
    "histGradRegressor = ensemble.HistGradientBoostingRegressor(random_state=rand_state)\n",
    "\n",
    "test_models = {\n",
    "    'logRegressor': logRegressor,\n",
    "    'baggingClassifier': baggingClassifier,\n",
    "    'histGradRegressor': histGradRegressor,\n",
    "    'stack_regressor': stack_regressor,\n",
    "    'stack_of_stacks_reg': stack_of_stacks_reg,\n",
    "    'voting_classifier': voting_classifier,\n",
    "    'voting_regressor': voting_regressor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_models.items():    \n",
    "    value.fit(X_train_scaled, y_train)\n",
    "    predictions = value.predict(X_train_scaled)\n",
    "\n",
    "    prediction_df = X_train.copy()\n",
    "    prediction_df['IsWin'] = y_train\n",
    "\n",
    "    threshold = 0.5\n",
    "    binary_predictions = np.where(predictions > threshold, 1, 0)\n",
    "    prediction_df['Predicted_Label'] = binary_predictions\n",
    "\n",
    "    accuracy = metrics.accuracy_score(prediction_df['IsWin'], prediction_df['Predicted_Label'])\n",
    "    print(\"Model: \", key)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(metrics.classification_report(prediction_df['IsWin'], prediction_df['Predicted_Label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "- After testing, it appears that the voting regressor is performing best on the data\n",
    "- will fine tune each of the estimator models that make up the voting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# fine tune GradientBoostingRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=ensemble.GradientBoostingRegressor(random_state=rand_state),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for HistGradientBoostingRegressor\n",
    "param_grid_hg = {\n",
    "    'max_iter': [100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'min_samples_leaf': [20, 40, 60]\n",
    "}\n",
    "\n",
    "# Grid search object\n",
    "grid_hg = GridSearchCV(\n",
    "    ensemble.HistGradientBoostingRegressor(random_state=rand_state),\n",
    "    param_grid_hg,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "grid_hg.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters for HistGradientBoostingRegressor:\", grid_hg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for XGBRegressor\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search object\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgboost.XGBRegressor(random_state=rand_state),\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "grid_xgb.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters for XGBRegressor:\", grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for BaggingRegressor\n",
    "param_grid_bag = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_samples': [0.8, 0.9, 1.0],\n",
    "    'max_features': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search object\n",
    "grid_bag = GridSearchCV(\n",
    "    ensemble.BaggingRegressor(random_state=rand_state),\n",
    "    param_grid_bag,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "grid_bag.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters for BaggingRegressor:\", grid_bag.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Export Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_best_params = {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
    "hgbr_best_params = {'learning_rate': 0.1, 'max_depth': 10, 'max_iter': 200, 'min_samples_leaf': 60}\n",
    "XGBR_best_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8\n",
    "    }\n",
    "bag_reg_best_params = {'max_features': 0.9, 'max_samples': 0.8, 'n_estimators': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the voting regressor with the best parameters\n",
    "voting_regressor = ensemble.VotingRegressor(\n",
    "    estimators=[\n",
    "        ('gradientBoost', ensemble.GradientBoostingRegressor(**gbr_best_params)),\n",
    "        ('histGradient', ensemble.HistGradientBoostingRegressor(**hgbr_best_params)),\n",
    "        ('xgbRegressor', xgboost.XGBRegressor(**XGBR_best_params)),\n",
    "        ('bagging', ensemble.BaggingRegressor(**bag_reg_best_params))\n",
    "    ]\n",
    ")\n",
    "voting_regressor.fit(X_train_scaled, y_train)\n",
    "yreg_pred = voting_regressor.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, yreg_pred)\n",
    "print(\"MSE of tuned VotingRegressor: \", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = voting_regressor.predict(X_train_scaled)\n",
    "\n",
    "prediction_df = X_train.copy()\n",
    "prediction_df['IsWin'] = y_train\n",
    "\n",
    "threshold = 0.5\n",
    "binary_predictions = np.where(predictions > threshold, 1, 0)\n",
    "prediction_df['Predicted_Label'] = binary_predictions\n",
    "\n",
    "accuracy = metrics.accuracy_score(prediction_df['IsWin'], prediction_df['Predicted_Label'])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(metrics.classification_report(prediction_df['IsWin'], prediction_df['Predicted_Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df['Predicted_Label'] = prediction_df['Predicted_Label'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df[\n",
    "    (prediction_df['IsWin'] == False)\n",
    "    & (prediction_df['Predicted_Label'] == True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the model to a file\n",
    "dump(model, 'voting_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "model = load('voting_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game_helper(teamID_1, teamID_2):\n",
    "    \"\"\" helper function to add the two selected teams agg stats into in DF \"\"\"\n",
    "    # select two teams and concat them into on df. then add the 'Loc_A', 'Loc_H', 'Loc_N' columns\n",
    "    predict_game = neutral_games[neutral_games['TeamID'] == teamID_1].reset_index(drop=True)\n",
    "    team2 = neutral_games[neutral_games['TeamID'] == teamID_2].reset_index(drop=True)\n",
    "\n",
    "    # for team2 drop the teamID and add prefix for columns\n",
    "    team2 = team2.add_prefix('opp_')\n",
    "\n",
    "    # predict_game = pd.concat([team1, team2], axis=1)\n",
    "    for col in team2.columns:\n",
    "        predict_game[col] = team2[col]\n",
    "\n",
    "    # add location columns\n",
    "    predict_game['Loc_A'] = False\n",
    "    predict_game['Loc_H'] = False\n",
    "    predict_game['Loc_N'] = True\n",
    "\n",
    "    return predict_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaded_model = create_game_helper(1152, 1541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TeamID', 'Score', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR',\n",
       "       'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'opp_TeamID', 'opp_Score',\n",
       "       'opp_FGM', 'opp_FGA', 'opp_FGM3', 'opp_FGA3', 'opp_FTM', 'opp_FTA',\n",
       "       'opp_OR', 'opp_DR', 'opp_Ast', 'opp_TO', 'opp_Stl', 'opp_Blk', 'opp_PF',\n",
       "       'Loc_A', 'Loc_H', 'Loc_N'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loaded_model.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
